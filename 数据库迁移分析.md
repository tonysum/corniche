# 数据库迁移分析：SQLite vs PostgreSQL

## 当前情况

- **数据库大小**：3.6GB
- **表数量**：2261 个表
- **磁盘空间**：只剩 6.4GB（使用率 99%）
- **错误**：`unable to open database file`（磁盘空间不足导致）

## 问题分析

### 当前问题
1. **磁盘空间不足**：这是导致错误的主要原因
2. **数据量持续增长**：每个交易对每个时间间隔都需要一个表
3. **SQLite 的限制**：
   - 并发写入性能较差
   - 在磁盘空间不足时容易出错
   - 单文件数据库，备份和恢复较慢

### SQLite 的限制

| 限制项 | SQLite | PostgreSQL |
|--------|--------|------------|
| 最大数据库大小 | 281TB（理论） | 32TB（单表），无限制（多表） |
| 并发写入 | 较差（文件锁） | 优秀（MVCC） |
| 索引性能 | 一般 | 优秀 |
| 查询优化 | 基础 | 高级 |
| 备份恢复 | 单文件，较慢 | 工具丰富，快速 |
| 磁盘空间要求 | 高（需要额外空间） | 中等（有 WAL 文件） |

## 解决方案

### 方案一：短期解决方案（推荐先执行）

#### 1. 清理磁盘空间
```bash
# 检查大文件
du -sh ~/* | sort -hr | head -20

# 清理系统缓存
sudo rm -rf ~/Library/Caches/*

# 清理 Docker（如果使用）
docker system prune -a

# 清理旧的数据备份
find ~/Documents/crypto/corniche/data -name "*.db.*" -mtime +30 -delete
```

#### 2. 优化 SQLite 数据库
```bash
# VACUUM 压缩数据库
sqlite3 data/crypto_data.db "VACUUM;"

# 重建索引
sqlite3 data/crypto_data.db "REINDEX;"
```

#### 3. 添加磁盘空间检查
在 `download_klines.py` 中添加磁盘空间检查，避免在空间不足时继续下载。

### 方案二：迁移到 PostgreSQL（长期方案）

#### 优势
1. **更好的并发性能**：支持多用户同时写入
2. **更好的查询性能**：高级查询优化器
3. **更好的可扩展性**：支持分区表、分片等
4. **更好的数据完整性**：更强的约束和事务支持
5. **更好的备份恢复**：pg_dump、pg_restore 等工具

#### 迁移步骤

1. **安装 PostgreSQL**
```bash
# macOS
brew install postgresql@15
brew services start postgresql@15

# Ubuntu/Debian
sudo apt-get install postgresql postgresql-contrib
sudo systemctl start postgresql
```

2. **创建数据库和用户**
```sql
CREATE DATABASE crypto_data;
CREATE USER crypto_user WITH PASSWORD 'your_password';
GRANT ALL PRIVILEGES ON DATABASE crypto_data TO crypto_user;
```

3. **修改数据库连接代码**

创建 `backend/db_postgres.py`：
```python
import os
from sqlalchemy import create_engine, text
from sqlalchemy.pool import QueuePool

# PostgreSQL 连接配置
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = os.getenv("DB_PORT", "5432")
DB_NAME = os.getenv("DB_NAME", "crypto_data")
DB_USER = os.getenv("DB_USER", "crypto_user")
DB_PASSWORD = os.getenv("DB_PASSWORD", "")

# 构建连接字符串
DATABASE_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# 创建引擎（使用连接池）
engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=10,
    max_overflow=20,
    pool_pre_ping=True,  # 自动重连
    echo=False
)

# 创建表的函数（需要修改表名格式，PostgreSQL 不支持数字开头的表名）
def create_table(table_name):
    # PostgreSQL 表名需要加引号，且不能以数字开头
    # 需要将 K15mBTCUSDT 转换为 k15m_btcusdt 或使用引号
    safe_table_name = f'"{table_name}"'  # 使用引号包裹
    
    with engine.connect() as conn:
        result = conn.execute(
            text(f"""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_name = '{table_name}'
                );
            """)
        )
        table_exists = result.scalar()
        
        if not table_exists:
            text_create = f"""
            CREATE TABLE {safe_table_name} (
                trade_date TEXT,
                open_time REAL,
                open REAL,
                high REAL,
                low REAL,
                close REAL,
                volume REAL,
                close_time REAL,
                quote_volume REAL,
                trade_count INTEGER,
                active_buy_volume REAL,
                active_buy_quote_volume REAL,
                reserved_field TEXT,
                diff REAL,
                pct_chg REAL,
                PRIMARY KEY (trade_date)
            );
            """
            conn.execute(text(text_create))
            conn.commit()
            print(f"Table '{table_name}' created successfully.")
        else:
            print(f"Table '{table_name}' already exists.")
        return table_exists
```

4. **数据迁移脚本**

创建 `backend/migrate_to_postgres.py`：
```python
"""
从 SQLite 迁移数据到 PostgreSQL
"""
import sqlite3
from sqlalchemy import create_engine, text
from db import engine as sqlite_engine
from db_postgres import engine as pg_engine
import pandas as pd

def migrate_table(table_name):
    """迁移单个表"""
    # 从 SQLite 读取数据
    with sqlite_engine.connect() as sqlite_conn:
        df = pd.read_sql(f'SELECT * FROM "{table_name}"', sqlite_conn)
    
    if df.empty:
        return
    
    # 写入 PostgreSQL
    with pg_engine.connect() as pg_conn:
        safe_table_name = f'"{table_name}"'
        df.to_sql(table_name, pg_conn, if_exists='append', index=False, method='multi')
        pg_conn.commit()
    
    print(f"Migrated {len(df)} rows from {table_name}")

def migrate_all_tables():
    """迁移所有表"""
    # 获取所有表名
    with sqlite_engine.connect() as sqlite_conn:
        result = sqlite_conn.execute(text(
            "SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'K%'"
        ))
        table_names = [row[0] for row in result]
    
    print(f"Found {len(table_names)} tables to migrate")
    
    for i, table_name in enumerate(table_names, 1):
        print(f"[{i}/{len(table_names)}] Migrating {table_name}...")
        try:
            migrate_table(table_name)
        except Exception as e:
            print(f"Error migrating {table_name}: {e}")
            continue
    
    print("Migration completed!")

if __name__ == "__main__":
    migrate_all_tables()
```

5. **更新所有引用**

需要修改以下文件：
- `backend/download_klines.py`
- `backend/data.py`
- `backend/services/data_service/main.py`
- `backend/services/backtest_service/main.py`
- 其他使用数据库的文件

6. **Docker Compose 配置**

在 `docker-compose.yml` 中添加 PostgreSQL 服务：
```yaml
services:
  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_DB: crypto_data
      POSTGRES_USER: crypto_user
      POSTGRES_PASSWORD: your_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped
    networks:
      - crypto-network

volumes:
  postgres_data:
```

## 推荐方案

### 短期（立即执行）
1. ✅ **清理磁盘空间**（至少释放 10GB）
2. ✅ **优化 SQLite 数据库**（VACUUM）
3. ✅ **添加磁盘空间检查**（防止再次发生）

### 中期（1-2周内）
1. ⚠️ **评估数据增长趋势**
2. ⚠️ **如果继续快速增长，考虑迁移到 PostgreSQL**

### 长期（如果数据量持续增长）
1. 🔄 **迁移到 PostgreSQL**
2. 🔄 **使用分区表优化查询性能**
3. 🔄 **设置自动备份策略**

## 迁移成本评估

| 项目 | 工作量 | 风险 |
|------|--------|------|
| 代码修改 | 中等（需要修改多个文件） | 低 |
| 数据迁移 | 中等（需要编写迁移脚本） | 中 |
| 测试验证 | 高（需要全面测试） | 中 |
| 部署配置 | 低（Docker 配置） | 低 |

## 结论

**当前建议**：
1. **先解决磁盘空间问题**（这是紧急问题）
2. **优化 SQLite 数据库**
3. **监控数据增长趋势**
4. **如果数据量继续快速增长（>10GB），再考虑迁移到 PostgreSQL**

**迁移时机**：
- 数据库大小 > 10GB
- 并发写入需求增加
- 查询性能明显下降
- 需要更高级的数据库功能（分区、复制等）
